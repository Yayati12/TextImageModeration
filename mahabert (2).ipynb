{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers"
      ],
      "metadata": {
        "id": "1nHH03zPVtaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Disable WandB by setting the environment variable\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "id": "Zy6nJ22HWtS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "if 'wandb' in sys.modules:\n",
        "    del sys.modules['wandb']\n"
      ],
      "metadata": {
        "id": "pncdJ-0xWtMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "QoX1iqN9VTQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets accelerate evaluate\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "import evaluate\n"
      ],
      "metadata": {
        "id": "tDDL4fJyVPLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset path\n",
        "train_df= pd.read_excel(\"/content/drive/My Drive/Colab Notebooks/L3Cube-MahaHate/4-class/hate_train.xlsx\")\n",
        "test_df= pd.read_excel(\"/content/drive/My Drive/Colab Notebooks/L3Cube-MahaHate/4-class/hate_test.xlsx\")\n",
        "valid_df= pd.read_excel(\"/content/drive/My Drive/Colab Notebooks/L3Cube-MahaHate/4-class/hate_valid.xlsx\")"
      ],
      "metadata": {
        "id": "kL_XGUc4VRe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train label distribution:\\n\", train_df['label'].value_counts())\n",
        "print(\"Valid label distribution:\\n\", valid_df['label'].value_counts())\n",
        "print(\"Test label distribution:\\n\", test_df['label'].value_counts())\n"
      ],
      "metadata": {
        "id": "FvAtpxJfVVsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "kyOsRICjVYOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['label'] = train_df['label'].str.strip().str.upper()\n",
        "valid_df['label'] = valid_df['label'].str.strip().str.upper()\n",
        "test_df['label']  = test_df['label'].str.strip().str.upper()\n"
      ],
      "metadata": {
        "id": "qfQ06-FyVag1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {'HATE': 0, 'OFFN': 1, 'PRFN': 2, 'NOT': 3}\n",
        "\n",
        "train_df['label'] = train_df['label'].map(label_map)\n",
        "valid_df['label'] = valid_df['label'].map(label_map)\n",
        "test_df['label'] = test_df['label'].map(label_map)\n"
      ],
      "metadata": {
        "id": "0bxQRBg8VcjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "k2V5k8nBVfJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['label'] = train_df['label'].astype(int)\n",
        "valid_df['label'] = valid_df['label'].astype(int)\n",
        "test_df['label']  = test_df['label'].astype(int)"
      ],
      "metadata": {
        "id": "3WWNcaPNVhcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train labels:\", train_df['label'].unique())\n",
        "print(\"Valid labels:\", valid_df['label'].unique())\n",
        "print(\"Test labels:\", test_df['label'].unique())\n"
      ],
      "metadata": {
        "id": "UZCQxwQsVjbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train label distribution:\\n\", train_df['label'].value_counts())\n",
        "print(\"Valid label distribution:\\n\", valid_df['label'].value_counts())\n",
        "print(\"Test label distribution:\\n\", test_df['label'].value_counts())\n"
      ],
      "metadata": {
        "id": "8gL--KpxVlME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load MahaHate-BERT tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"l3cube-pune/mahahate-bert\")\n",
        "\n",
        "# Tokenize function\n",
        "def tokenize_data(texts):\n",
        "    return tokenizer(\n",
        "        texts.tolist(),\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "# Tokenize each split\n",
        "train_encodings = tokenize_data(train_df['text'])\n",
        "valid_encodings = tokenize_data(valid_df['text'])\n",
        "test_encodings  = tokenize_data(test_df['text'])\n"
      ],
      "metadata": {
        "id": "DwanDWz9VnTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class HateSpeechDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = torch.tensor(labels.values, dtype=torch.long)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Create dataset objects\n",
        "train_dataset = HateSpeechDataset(train_encodings, train_df['label'])\n",
        "valid_dataset = HateSpeechDataset(valid_encodings, valid_df['label'])\n",
        "test_dataset  = HateSpeechDataset(test_encodings, test_df['label'])\n"
      ],
      "metadata": {
        "id": "5FZba7WqVpYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# Load the model while ignoring size mismatch in the classification head\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"l3cube-pune/mahahate-bert\",\n",
        "    num_labels=4,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "LKfXKe24VrS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Compute metrics function\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    f1 = f1_score(labels, preds, average='macro')\n",
        "    return {\"accuracy\": acc, \"f1\": f1}\n",
        "\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    report_to=\"none\",  # Disable reporting to wandb\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ],
      "metadata": {
        "id": "3lw-OjaxVwEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Disable WandB by setting the environment variable\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "id": "qVbNGeFxYw6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "-A7si4aCWyuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "lYbYYE0hW1HZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = \"/content/drive/My Drive/MarathiHateModel\"\n",
        "trainer.save_model(model_save_path)\n",
        "tokenizer.save_pretrained(model_save_path)\n"
      ],
      "metadata": {
        "id": "O2-kaWUSSA97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"marathi-hate-speech-transformer\")\n",
        "tokenizer.save_pretrained(\"marathi-hate-speech-transformer\")\n"
      ],
      "metadata": {
        "id": "k8VKplEzW3FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# Load from your saved directory\n",
        "tokenizer = BertTokenizer.from_pretrained(\"marathi-hate-speech-transformer\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"marathi-hate-speech-transformer\")\n"
      ],
      "metadata": {
        "id": "zJ0iC0qjW5X3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextClassificationPipeline\n",
        "\n",
        "classifier = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True, device=0)  # set device=-1 if no GPU\n"
      ],
      "metadata": {
        "id": "FinScZ0PW7OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = [\n",
        "    \"तू खूप चांगला आहेस\",                 # Positive / NOT\n",
        "    \"मूर्ख आहेस तू\",                     # Offensive\n",
        "    \"तुझ्यासारख्यांनी देश सोडावा\",        # Hateful\n",
        "    \"बिनकामाचा मनुष्य\"                  # Profane or Offensive\n",
        "]\n"
      ],
      "metadata": {
        "id": "DxbkDl_5W9Fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = classifier(samples)\n",
        "for i, res in enumerate(results):\n",
        "    print(f\"Text: {samples[i]}\")\n",
        "    for label_score in res:\n",
        "        print(f\"  Label {label_score['label']}: {label_score['score']:.4f}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "ytdTPqqdW-w0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {\n",
        "    \"LABEL_0\": \"HATE\",\n",
        "    \"LABEL_1\": \"OFFN\",\n",
        "    \"LABEL_2\": \"PRFN\",\n",
        "    \"LABEL_3\": \"NOT\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "Zik4n9_CXAm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, res in enumerate(results):\n",
        "    print(f\"Text: {samples[i]}\")\n",
        "    for label_score in res:\n",
        "        label_name = id2label[label_score['label']]\n",
        "        print(f\"  Label {label_name}: {label_score['score']:.4f}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "VdO_cqh7XCSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio --quiet\n",
        "import gradio as gr\n"
      ],
      "metadata": {
        "id": "BM3hpxXhXD99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load pipeline\n",
        "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, return_all_scores=True)\n",
        "\n",
        "# Label mapping\n",
        "id2label = {\n",
        "    \"LABEL_0\": \"HATE\",\n",
        "    \"LABEL_1\": \"OFFN\",\n",
        "    \"LABEL_2\": \"PRFN\",\n",
        "    \"LABEL_3\": \"NOT\"\n",
        "}\n",
        "\n",
        "# Prediction function\n",
        "def classify_text(text):\n",
        "    results = classifier(text)[0]\n",
        "    output = f\"Text: {text}\\n\"\n",
        "    for item in results:\n",
        "        label = id2label[item['label']]\n",
        "        score = round(item['score'], 4)\n",
        "        output += f\"Label {label}: {score:.4f}\\n\"\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "Wunb6NLvXFqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface(\n",
        "    fn=classify_text,\n",
        "    inputs=gr.Textbox(label=\"Enter Marathi Text\", placeholder=\"Type here...\", lines=2),\n",
        "    outputs=gr.Textbox(label=\"Prediction\"),\n",
        "    title=\"Marathi Hate Speech Detector\",\n",
        "    description=\"Click 'Check Toxicity' to see label-wise probabilities.\",\n",
        "    live=False,\n",
        "    allow_flagging=\"never\",\n",
        "    theme=\"soft\",\n",
        "    examples=[\n",
        "        [\"मूर्ख आहेस तू\"],\n",
        "        [\"तू खूप चांगला आहेस\"],\n",
        "        [\"हे लोक देशद्रोही आहेत, त्यांना गोळी मारायला पाहिजे\"],\n",
        "        [\"माझ्या आईने आज माझ्या आवडीचं जेवण केलं.\"],\n",
        "        [\"fu*k you, तुला काय कळतं?\"],\n",
        "        [\"मला मराठी साहित्य वाचायला आवडतं.\"],\n",
        "\n",
        "    ]\n",
        ")\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "SNRp9UskXH5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l4cYwbB1hCVk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}